
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta content="Interview resource of Data Science focusing on Anomaly Detection." lang="en" name="description" xml:lang="en" />
<meta content="interview, data science, machine learning, Anomaly Detection, Isolation Forest" name="keywords" />
<meta content="en_US" property="og:locale" />

    <title>Anomaly Detection &#8212; The Data Science Interview Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://dipranjan.github.io/dsinterviewqns/contents/Algorithms/Anomaly Detection.html" />
    <link rel="shortcut icon" href="../../_static/logo.gif"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Big O Analysis" href="Big%20O%20Analysis.html" />
    <link rel="prev" title="Time Series Analysis" href="Time%20Series%20Analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-60403888-2', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">✨Book Last updated on 30 Oct'22 ✨ PDF version of the book is now available 🥳 Check the footer for the link!!!</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">The Data Science Interview Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    About this Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Journey of this project
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../To%20Do%20List.html">
   Log
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Statistics/Probability%20Basics.html">
   Probability Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Statistics/Probability%20Distribution.html">
   Probability Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Statistics/Central%20Limit%20Theorem.html">
   Central Limit Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Statistics/Bayesian%20vs%20Frequentist%20Reasoning.html">
   Bayesian vs Frequentist Reasoning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Statistics/Hypothesis%20Testing.html">
   Hypothesis Testing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model Building
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Data/Data.html">
   Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data/Scaling.html">
     Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data/Missing%20Value.html">
     Missing Value
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data/Outlier.html">
     Outlier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data/Sampling.html">
     Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Data/Hyperparameter%20optimization.html">
   Hyperparameter Optimization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Diagnostics.html">
   Bias/Variance Tradeoff
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Regression.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Generative%20VS%20Discriminative%20Models.html">
   Generative vs Discriminative Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tree%20based%20approaches.html">
   Tree based approaches
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Time%20Series%20Analysis.html">
   Time Series Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Anomaly Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Big%20O%20Analysis.html">
   Big O Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Network
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../NN/Neural%20Network.html">
   Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../NN/Recurrent%20Neural%20Network.html">
   Recurrent Neural Network
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../NLP/Lexical%20Processing.html">
   Lexical Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../NLP/Syntactic%20Processing.html">
   Syntactic Processing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Story Telling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../StoryTelling/Visualization.html">
   Visualization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Python/Basics.html">
   Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Python/Data%20Manipulation.html">
   Data Manipulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Python/Statistics.html">
   Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Python/NLP.html">
   NLP
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SQL
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Select.html">
   SQL Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Joins.html">
   Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Temporary%20Datasets.html">
   Temporary Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Windows%20Functions.html">
   Windows Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Time.html">
   Time
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../SQL/Problems.html">
   Problems
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Excel
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Excel/Excel%20Basics.html">
   Excel Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Excel/Data%20Manipulation.html">
   Data Manipulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Excel/Time%20and%20Date.html">
   Time and Date
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning Frameworks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../MLFramework/PyCaret.html">
   PyCaret
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../MLFramework/Tensorflow/Tensorflow.html">
   Tensorflow
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../MLFramework/Tensorflow/Basics.html">
     Basics
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Analytical Thinking
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Analytical%20Thinking/Business%20Scenarios.html">
   Business Scenarios
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analytical%20Thinking/Industry%20Application.html">
   Industry Application
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analytical%20Thinking/Behavioral%20-%20Management.html">
   Behavioral - Management
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <div>
    <script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="dearc" data-color="#FF5F5F" data-emoji=""  data-font="Bree" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>
</div>

            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/dipranjan/dsinterviewqns/issues/new?title=Issue%20on%20page%20%2Fcontents/Algorithms/Anomaly Detection.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/contents/Algorithms/Anomaly Detection.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types">
   Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods-of-detecting-anamolies">
   Methods of detecting Anamolies
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#isolation-forest">
     Isolation Forest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-outlier-factor">
     Local Outlier Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#robust-covariance">
     Robust Covariance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-class-svm">
     One Class SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-class-svm-sgd">
     One Class SVM (SGD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cluster-based-local-outlier-factor-cblof">
     Cluster-based Local Outlier Factor (CBLOF)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#histogram-based-outlier-detection-hbos">
     Histogram-based Outlier Detection (HBOS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn">
     KNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questions">
   Questions
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Anomaly Detection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types">
   Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods-of-detecting-anamolies">
   Methods of detecting Anamolies
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#isolation-forest">
     Isolation Forest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-outlier-factor">
     Local Outlier Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#robust-covariance">
     Robust Covariance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-class-svm">
     One Class SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-class-svm-sgd">
     One Class SVM (SGD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cluster-based-local-outlier-factor-cblof">
     Cluster-based Local Outlier Factor (CBLOF)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#histogram-based-outlier-detection-hbos">
     Histogram-based Outlier Detection (HBOS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn">
     KNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questions">
   Questions
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="anomaly-detection">
<h1>Anomaly Detection<a class="headerlink" href="#anomaly-detection" title="Permalink to this headline">#</a></h1>
<p>An anomaly is something that differs from a norm: a deviation, an exception. In software engineering, by anomaly we understand a rare occurrence or event that doesn’t fit into the pattern, and, therefore, seems suspicious.</p>
<section id="types">
<h2>Types<a class="headerlink" href="#types" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong>Global outliers:</strong> When a data point assumes a value that is far outside all the other data point value ranges in the dataset, it can be considered a global anomaly. In other words, it’s a rare event.</p></li>
<li><p><strong>Contextual outliers:</strong> When an outlier is called contextual it means that its value doesn’t correspond with what we expect to observe for a similar data point in the same context. Contexts are usually temporal, and the same situation observed at different times can be not an outlier.</p></li>
<li><p><strong>Collective outliers:</strong> Collective outliers are represented by a subset of data points that deviate from the normal behavior.</p></li>
</ul>
</section>
<section id="methods-of-detecting-anamolies">
<h2>Methods of detecting Anamolies<a class="headerlink" href="#methods-of-detecting-anamolies" title="Permalink to this headline">#</a></h2>
<p>There are three categories of outlier detection, namely, supervised, semi-supervised, and unsupervised:</p>
<ul class="simple">
<li><p><strong>Supervised:</strong> Requires fully labeled training and testing datasets. An ordinary classifier is trained first and applied afterward. Here, the quality of the training dataset is very important and it is a lot of manual work involved since somebody needs to collect and label examples. Due to this mostly unsupervised methods are used in Anamoly detection.</p></li>
<li><p><strong>Semi-supervised:</strong> Uses training and test datasets, whereas training data only consists of normal data without any outliers. A model of the normal class is learned and outliers can be detected afterward by deviating from that model.</p></li>
<li><p><strong>Unsupervised:</strong> Does not require any labels; there is no distinction between a training and a test dataset Data is scored solely based on intrinsic properties of the dataset.</p></li>
</ul>
<p>And three fundamental approaches to detect anomalies are based on:</p>
<ul class="simple">
<li><p><strong>By Density:</strong> Normal points occur in dense regions, while anomalies occur in sparse regions</p></li>
<li><p><strong>By Distance:</strong> Normal point is close to its neighbors and anomaly is far from its neighbors</p></li>
<li><p><strong>By Isolation:</strong> The term isolation means ‘separating an instance from the rest of the instances’. Since anomalies are ‘few and different’ and therefore they are more susceptible to isolation.</p></li>
</ul>
<section id="isolation-forest">
<h3>Isolation Forest<a class="headerlink" href="#isolation-forest" title="Permalink to this headline">#</a></h3>
<p>Isolation Forest is an unsupervised anomaly detection algorithm that uses a random forest algorithm (decision trees) under the hood to detect outliers in the dataset. The algorithm tries to split or divide the data points such that each observation gets isolated from the others. Usually, the anomalies lie away from the cluster of data points, so it’s easier to isolate the anomalies compare to the regular data points.</p>
<figure class="align-default" id="image17">
<a class="reference internal image-reference" href="../../_images/image181.PNG"><img alt="../../_images/image181.PNG" src="../../_images/image181.PNG" style="width: 823.5px; height: 233.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 24 </span><span class="caption-text">Partitioning of Anomaly and Regular data point <a class="reference external" href="https://towardsdatascience.com/5-anomaly-detection-algorithms-every-data-scientist-should-know-b36c3605ea16">Source</a></span><a class="headerlink" href="#image17" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="local-outlier-factor">
<h3>Local Outlier Factor<a class="headerlink" href="#local-outlier-factor" title="Permalink to this headline">#</a></h3>
<p>It takes the density of data points into consideration to decide whether a point is an anomaly or not. The local outlier factor computes an anomaly score called anomaly score that measures how isolated the point is with respect to the surrounding neighborhood. It takes into account the local as well as the global density to compute the anomaly score.</p>
<figure class="align-default" id="id1">
<a class="reference internal image-reference" href="../../_images/image191.PNG"><img alt="../../_images/image191.PNG" src="../../_images/image191.PNG" style="width: 991.1999999999999px; height: 415.2px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 25 </span><span class="caption-text">Local Outlier Factor Formulation <a class="reference external" href="https://medium.com/mlpoint/local-outlier-factor-a-way-to-detect-outliers-dde335d77e1a">Source</a></span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="robust-covariance">
<h3>Robust Covariance<a class="headerlink" href="#robust-covariance" title="Permalink to this headline">#</a></h3>
<p>For gaussian independent features, simple statistical techniques can be employed to detect anomalies in the dataset. For a gaussian/normal distribution, the data points lying away from 3rd deviation can be considered as anomalies.</p>
<p>For a dataset having all the feature gaussian in nature, then the statistical approach can be generalized by defining an elliptical hypersphere that covers most of the regular data points, and the data points that lie away from the hypersphere can be considered as anomalies.</p>
</section>
<section id="one-class-svm">
<h3>One Class SVM<a class="headerlink" href="#one-class-svm" title="Permalink to this headline">#</a></h3>
<p>A regular SVM algorithm tries to find a hyperplane that best separates the two classes of data points. For one-class SVM where we have one class of data points, and the task is to predict a hypersphere that separates the cluster of data points from the anomalies.</p>
</section>
<section id="one-class-svm-sgd">
<h3>One Class SVM (SGD)<a class="headerlink" href="#one-class-svm-sgd" title="Permalink to this headline">#</a></h3>
<p>One-class SVM with SGD solves the linear One-Class SVM using Stochastic Gradient Descent. The implementation is meant to be used with a kernel approximation technique to obtain results similar to <code class="docutils literal notranslate"><span class="pre">sklearn.svm.OneClassSVM</span></code> which uses a Gaussian kernel by default.</p>
</section>
<section id="cluster-based-local-outlier-factor-cblof">
<h3>Cluster-based Local Outlier Factor (CBLOF)<a class="headerlink" href="#cluster-based-local-outlier-factor-cblof" title="Permalink to this headline">#</a></h3>
<p>The CBLOF calculates the outlier score based on cluster-based local outlier factor. An anomaly score is computed by the distance of each instance to its cluster center multiplied by the instances belonging to its cluster.</p>
</section>
<section id="histogram-based-outlier-detection-hbos">
<h3>Histogram-based Outlier Detection (HBOS)<a class="headerlink" href="#histogram-based-outlier-detection-hbos" title="Permalink to this headline">#</a></h3>
<p>HBOS assumes the feature independence and calculates the degree of anomalies by building histograms. In multivariate anomaly detection, a histogram for each single feature can be computed, scored individually and combined at the end.</p>
</section>
<section id="knn">
<h3>KNN<a class="headerlink" href="#knn" title="Permalink to this headline">#</a></h3>
<p>It is one of the simplest methods in anomaly detection. For a data point, its distance to its kth nearest neighbor could be viewed as the outlier score.</p>
<p>For Univariate Analysis Isolation Forest can be used to detect outliers that returns the anomaly score of each sample. Isolation Forest is a tree-based model. In these trees, partitions are created by first randomly selecting a feature and then selecting a random split value between the minimum and maximum value of the selected feature. In multivariate anomaly detection, outlier is a combined unusual score on at least two variables. For Multivariate Analysis multiple options are avaliable other than isolation forest:</p>
</section>
</section>
<section id="questions">
<h2>Questions<a class="headerlink" href="#questions" title="Permalink to this headline">#</a></h2>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: [AKAMAI] Anomaly in Univariate Dataset</p>
<p><strong>Asked By - AKAMAI</strong></p>
<p>If given a univariate dataset, how would you design a function to detect anomalies?</p>
<p>What if the data is bivariate?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p><strong>Reference:</strong> <a class="reference external" href="https://towardsdatascience.com/anomaly-detection-for-dummies-15f148e559c1">📖Explanation</a></p>
<p>Anomaly detection is the process of identifying unexpected items or events in data sets, which differ from the norm. And anomaly detection is often applied on unlabeled data which is known as unsupervised anomaly detection. Anomaly detection has two basic assumptions:</p>
<ul class="simple">
<li><p>Anomalies only occur very rarely in the data.</p></li>
<li><p>Their features differ from the normal instances significantly.</p></li>
</ul>
<p>This is part is mentioned above too, for Univariate Analysis Isolation Forest can be used to detect outliers that returns the anomaly score of each sample. Isolation Forest is a tree-based model. In these trees, partitions are created by first randomly selecting a feature and then selecting a random split value between the minimum and maximum value of the selected feature.</p>
<p>In multivariate anomaly detection, outlier is a combined unusual score on at least two variables. For Multivariate Analysis multiple options are avaliable other than isolation forest:</p>
<ul class="simple">
<li><p>The Cluster-based Local Outlier Factor (CBLOF)</p></li>
<li><p>Histogram-based Outlier Detection (HBOS)</p></li>
<li><p>KNN</p></li>
</ul>
<p>An ensemble of these methods can be used to finalize the anamolies. Always visually investigate some of the anomalies.</p>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Swamping VS Masking</p>
<p>What are the Swamping and Masking problems in Anomaly Detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>Since anomalies are rare events, making it very difficult to label them with high accuracy, swamping is the phenomenon of labeling normal events as anomalies.</p></li>
<li><p>When clustering algorithms are used, the data points belonging to different clusters get merged into one cluster, if the number of segments in the dataset is not known, this causes the outlier cluster to be merged to a cluster with normal data points. This causes the outliers to not be detected. This is defined as masking.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Uniform Distribution VS Normal Distribution</p>
<p>What are the differences in Anomalies for Uniform Distribution and Normal Distribution in One-Dimensional Data?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p>Keep in mind how the Uniform and Normal Distribution looks like.</p>
<p><strong>Uniform</strong></p>
<ul class="simple">
<li><p>When data is distributed uniformly over a finite range, the mean and standard deviation merely characterize the range of values.</p></li>
<li><p>One possible indication of anomalous behavior could be that a small neighborhood contains substantially fewer or more data points than expected from a uniform distribution.</p></li>
</ul>
<p><strong>Normal</strong></p>
<ul class="simple">
<li><p>A normal distribution follows the empirical rule, which states that 68%, 95%, and 99.7% of the values lie within one, two, and three standard deviations of the mean, respectively.</p></li>
<li><p>About 0.1% of the points are more than <span class="math notranslate nohighlight">\(3 *\sigma\)</span> (three standard deviations) away from the mean, hence, it is taken as the threshold and points beyond that distance from the mean are declared to be anomalous.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: SVM VS Logistic Regression</p>
<p>Compare SVM and Logistic Regression in handling outliers</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>For Logistic Regression, outliers can have an unusually large effect on the estimate of logistic regression coefficients. It will find a linear boundary if it exists to accommodate the outliers. To solve the problem of outliers, sometimes a sigmoid function is used in logistic regression.</p></li>
<li><p>For SVM, outliers can make the decision boundary deviate severely from the optimal hyperplane. One way for SVM to get around the problem is to intrduce slack variables. There is a penalty involved with using slack variables, and how SVM handles outliers depends on how this penalty is imposed.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Outlier VS Novelty</p>
<p>Explain the difference between Outlier Detection vs Novelty Detection</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>The training data contains outliers which are defined as observations that are far from the others. Outlier detection estimators thus try to fit the regions where the training data is the most concentrated, ignoring the deviant observations.</p></li>
<li><p>The training data is not polluted by outliers and we are interested in detecting whether a new observation is an outlier. In this context an outlier is also called a novelty.</p></li>
</ul>
<p>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection.</p>
<p>In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</p>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Out of Distribution VS Anomaly</p>
<p>What is the difference between Out of Distribution and Anomaly Detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>Out of distribution (OOD) data refers to data that was collected at a different time, and possibly under different conditions or in a different environment than the data collected to create the model. It can be said that the data is from a different distribution.</p></li>
<li><p>After the out of distribution data is collected, the model can perform either Novelty detection or Anomaly detection.</p></li>
<li><p>Novelty data is the data that is in-distribution. Novelty detection checks whether the new data is in-distribution or not.</p></li>
<li><p>Anomaly detection is used to test the data to see if it is different than what the model was trained on.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Resolution-Based Outlier Detection</p>
<p>What is a Resolution-Based Outlier Detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>The resolution-based outlier detection is an approach to address the problem of parameter value determination by measuring the outlierness of an observation <span class="math notranslate nohighlight">\(p ∈ D\)</span> at different resolutions, and aggregating the results.</p></li>
<li><p>In this algorithm, at the highest resolution, all observations are isolated points and thus considered to be outliers whereas at the lowest resolution all observations belong to one cluster and none is considered to be an outlier.</p></li>
<li><p>As the resolution decreases from its highest value to the lowest value some observations in D begin to form clusters leaving other observations out of the clusters, and this phenomenon is captured in the resolution based outlier detection approach.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Change Detection</p>
<p>What is the Change Detection problem in Anomaly Detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<ul class="simple">
<li><p>Change detection or change point detection tries to identify times when the probability distribution of a time series changes.</p></li>
<li><p>Change detection is generally used to detect anomalous behavior.</p></li>
</ul>
<p>Change point detection is great for the following cases:</p>
<ul class="simple">
<li><p>Detecting anomalous sequences/states in a time series.</p></li>
<li><p>Detecting the average velocity of unique states in a time series.</p></li>
<li><p>Detecting a sudden change in a time series state in real-time.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Drawbacks of Density Based Method</p>
<p>Can you tell some shortcomings of density based anomaly detection methods?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p>Density-based outlier detection method investigates the density of an object and that of its neighbors. Here, an object is identified as an outlier if its density is relatively much lower than that of its neighbors.
Many real-world data sets demonstrate a more complex structure, where objects may be considered outliers with respect to their local neighborhoods, rather than with respect to the global data distribution.</p>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Distance based Outlier detection</p>
<p>Explain Distance based Outlier detection methods?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p>A distance-based outlier detection method consults the neighborhood of an object, which is defined by a given radius. An object is then considered an outlier if its neighborhood does not have enough other points. This is termed as Distance-Based Outlier Detection Methods.</p>
<ul class="simple">
<li><p>Distance-Based Methods usually depend on a Multi-dimensional Index, Which is used to retrieve the neighborhood of each object to see if it contains sufficient points. If there are insufficient points, then the object is termed an outlier.</p></li>
<li><p>Distance-Based methods scale better to multi-dimensional space and can be computed more efficiently than the statistical-based method. Identifying Distance-based outliers is an important and useful data mining activity. The main disadvantage of distance-based methods is that distance-based outlier detection is based on a single value of a custom parameter. This can cause significant problems if the dataset contains both dense and sparse regions.</p></li>
</ul>
<p>Outlier detection methods can be categorized according to whether the sample of data for analysis is given with expert-provided labels that can be used to build an outlier detection model. In this case, the detection methods are supervised, semi-supervised, or unsupervised. Alternatively, outlier detection methods may be organized according to their assumptions regarding normal objects versus outliers. This categorization includes statistical methods, proximity-based methods, and clustering-based methods.</p>
<p>Algorithms For Mining Distance-Based Outliers:</p>
<ul class="simple">
<li><p><strong>Index-based algorithm:</strong> The index-based algorithm facilitates multidimensional indexing structures, including R-trees or <span class="math notranslate nohighlight">\(k-d\)</span> trees, to search for neighbors of each object <span class="math notranslate nohighlight">\(o\)</span> inside radius <span class="math notranslate nohighlight">\(d\)</span> around that object.    Once  <span class="math notranslate nohighlight">\(K  (K  =  N(1-p))\)</span> neighbors of object <span class="math notranslate nohighlight">\(o\)</span> are discovered, it is accessible that <span class="math notranslate nohighlight">\(o\)</span> is not an outlier. This algorithm has the lowest case complexity of <span class="math notranslate nohighlight">\(O (k * n^2)\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the dimensionality, and <span class="math notranslate nohighlight">\(n\)</span> is the number of objects in the data set.</p></li>
<li><p><strong>Nested-loop algorithm:</strong> The nested loop algorithm has the same evaluation complexity as the index-based algorithm but avoids building index structures and minimizes the amount of I/O. It splits the memory buffer in half and puts the data into several logical blocks.</p></li>
<li><p><strong>Cell-based algorithm:</strong> It avoids the <span class="math notranslate nohighlight">\(O(n^2)\)</span> computational complexity and develops a cell-based algorithm for memory-resident datasets. Its complexity is <span class="math notranslate nohighlight">\(O(c*k + n)\)</span>, where <span class="math notranslate nohighlight">\(c\)</span> is a constant based on the number of cells and <span class="math notranslate nohighlight">\(k\)</span> is the dimension.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Dictionary learning in Anamoly detection</p>
<p>Can you explain Dictionary learning in Anamoly detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p>Dictionary learning generalizes the assumption that “typical” data points inhabit a low-dimensional subspace of the ambient space by proposing that points may all lie in the union of many very low-dimensional subspaces. Specifically, using sparse coding techniques, dictionary learning represents each data point as a linear combination of only a few basis elements, ie. dictionary atoms. Since each data point is closely related to its corresponding atoms, points using the same atoms are presumably semantically related, naturally grouping the data. This suggests that anomalous data will exhibit at least one of three properties:</p>
<ul class="simple">
<li><p>Anomalous data will not be well represented by a learned dictionary as long as the dictionary is constrained to a sufficiently small number of atoms. Therefore, anomalies can be identified as having large residuals.</p></li>
<li><p>The learned dictionary will be more influenced by anomalies than by data points that follow the greater trend, since anomalies will be much farther from the union of the spans of small subsets of the dictionary than from the span of the entire dictionary. That is, anomalous data will have high leverage on the model relative to “typical” data.</p></li>
<li><p>If the dictionary contains a sufficiently large number of atoms or the anomalies occur frequently, these data points will fit the model well but will use “rare” basis atoms. These atoms are typically not used by regular data and are included in the learned model primarily to “accommodate” the anomalous data. Alternatively, typical basis elements may be used in atypical combinations to represent anomalous points.</p></li>
</ul>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Problem: Autoencoder in Anamoly Detection</p>
<p>How are Autoencoders used in Anamoly Detection?</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Solution:</p>
<p>One of the predominant use cases of the Autoencoder is anomaly detection. Think about cases like IoT devices, sensors in CPU, and memory devices which work very nicely as per functions. Still, when we collect their fault data, we have majority positive classes and significantly less percentage of minority class data, also known as imbalance data. Sometimes it is tough to label the data or expensive labelling the data, so we know the expected behaviour of data.</p>
<p>We pass Autoencoder with majority classes(normal data). The training objective is to minimize the reconstruction error, and the training objective is to minimize this. as training progresses, the model weights for the encoder and decoder are updated. The encoder is a downsampler, and the decoder is an upsampler. Encoder and decoder can be ANN, CNN, or LSTM neural network.</p>
<p>What AutoEncoder does? It learns the reconstruction function that works with normal data, and we can use this Model for anomaly detection. We get low reconstruction error for normal data and high for abnormal data(minority class).</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents\Algorithms"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Time%20Series%20Analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Time Series Analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Big%20O%20Analysis.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Big O Analysis</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Dip Ranjan Chatterjee | © MIT License - 2021<br/>
  
    <div class="extra_footer">
      <p>
<a href="https://dearc.medium.com/membership" target="_blank"><img src="https://img.shields.io/badge/Support-Medium%20Referral-lightgrey?style=flat-square&logo=appveyor.svg" alt="Medium Membership"></a>
<a href="https://www.linkedin.com/company/the-data-science-interview-book/?lipi=urn%3Ali%3Apage%3Ad_flagship3_feed%3BeglbXB3xT0mopZBzReqMEQ%3D%3D" target="_blank"><img src="https://img.shields.io/badge/Follow-LinkedIn-0077B5?style=flat-square&logo=appveyor.svg" alt="Follow LinkedIn"></a>
<a href="https://github.com/dipranjan/dsinterviewqns/discussions" target="_blank"><img src="https://img.shields.io/badge/Discussion%20Forum-%F0%9F%99%8A%20%20%F0%9F%99%88%20%20%F0%9F%99%89-0172B3?style=flat-square&logo=appveyor.svg" alt="Discussion Forum"></a>
<a href="https://www.buymeacoffee.com/dearc/e/88363" target="_blank"><img src="https://img.shields.io/badge/BUY-PDF%20Version%20%F0%9F%93%96-red?style=flat-square&logo=appveyor.svg" alt="Buy Book"></a>
</p>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>